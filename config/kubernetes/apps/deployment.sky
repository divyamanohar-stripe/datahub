# DO NOT EDIT: http://go/vendor-skycfg
"""
Functions for creating and configuring Kubernetes [Deployment][]s, which are the main way that
we run long-running service workloads on Kubernetes.

[deployment]: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/
"""
load("config/kubernetes/apps/strategy.sky", "rolling_update_strategy")
load("config/kubernetes/core/pod.sky", "all_containers", "main_container")
load("config/kubernetes/helpers/bluegreen.sky", "with_blue_green_traffic_shifting", "add_blue_green_strategy")
load("config/kubernetes/helpers/warning.sky", "warn")
load("config/kubernetes/core/lifecycle.sky", "prestop_all_containers", "prestop_all_infra_sidecars", "DEFAULT_GRACE_PERIOD_SECONDS", "grace_period", "generate_prestop_sleep_action", "DEFAULT_ENVOY_HEALTHCHECK_PROPAGATION_TIME")
load("config/kubernetes/helpers/rolling.sky", "add_rolling_speed_override")
load("config/kubernetes/meta/metadata.sky", "render_metadata", "render_selector", "get_availability_tier_from_metadata")
load("config/kubernetes/networking/public/networking.sky", "networking")
load("config/kubernetes/plugins/compose.sky", "compose_plugins")
load("config/kubernetes/plugins/types.sky", "deployment_plugin")
load("config/kubernetes/sidecars/metrics.sky", "metrics")
load("config/kubernetes/sidecars/sansshell.sky", "sansshell_sidecar")
load("config/kubernetes/helpers/context.sky", "get_env", "get_blue_green_color", "get_render_yaml")
load("config/kubernetes/core/volume.sky", "volume_mount_all_containers")
load("config/kubernetes/helpers/ldap.sky", "mount_ldap_host_volumes", "LDAP_MOUNT_NAME")
load("config/kubernetes/helpers/proto_or_yaml.sky", "Deployment", "DeploymentSpec")

def deployment(ctx, *plugins, shared_msp=False, mount_ldap_volumes=True, disable_default_metrics_sidecar=False, **kwargs):
    """
    Schedule one or more instances of a stateless service.

    A Deployment allows running one of more instances (pods) of a service, and facilitates smoothly
    rolling out new versions of those instances when the configuration is changed. Most stateless
    services that run on Kubernetes are described by a deployment.

    Args:
        ctx: The Skycfg context from the `main` function.
        *plugins: One or more plugins to configure the service.
        shared_msp: boolean which is True iff the deployment should go to shared MSP (default is False)
        mount_ldap_volumes: Whether we should auto-apply the
            `mount_ldap_host_volumes` plugin. Defaults to true to mirror pre-MSP, but
            some applications may wish to opt-out if it conflicts with other mounts
            in their countainer image.
        **kwargs: Options for the [DeploymentSpec](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.17/#deploymentspec-v1-apps).
            A shortcut for the `deployment_options` plugin.

    Returns:
        A [Deployment](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.17/#deployment-v1-apps)
        Kubernetes protobuf message describing the configuration of the service.
    """

    deployment = {
        "render": _render_deployment,
        "type": "deployment",
        "metadata": {},
        "shared_msp": shared_msp,
        "registered_services": [],
        "kwargs": {},
        "networking_config": None,
        "metrics_config": None,
    }

    all_plugins = [
        deployment_options(
            strategy = rolling_update_strategy(
                ctx,
                max_unavailable = 1,
                max_surge = 1,
            ),
            # allow plenty of time for autoscale-srv to scale up capacity for the deployment
            progressDeadlineSeconds = 3600,
        ),
        add_blue_green_strategy(), # Do this early to allow overrides by the user's plugins
    ]
    all_plugins.extend(plugins)
    all_plugins.append(deployment_options(**kwargs))
    all_plugins.append(with_blue_green_traffic_shifting())
    all_plugins.append(add_rolling_speed_override())

    plugin = compose_plugins(*all_plugins)
    _apply_plugin(ctx, plugin, deployment)

    # for shared msp, services get registered at update time, but the plugin needs them
    # at create time, so we init and update the networking plugin after all the others
    if shared_msp:
        namespace = deployment["metadata"].get("namespace", None)
        if namespace == None:
            fail("Namespace not set for shared MSP deployment. Perhaps missing a namespace param to your pod?")

        # If no grace period is set, use the default
        _apply_plugin(ctx, compose_plugins(grace_period(DEFAULT_GRACE_PERIOD_SECONDS, overwrite = False)), deployment)
        pod_termination_grace_period_seconds = deployment["pod"]["grace_period"]

        networking_plugin = networking(
            ctx,
            namespace=namespace,
            availability_tier=get_availability_tier_from_metadata(deployment["metadata"]),
            host_network=False,
            register_services=deployment['registered_services'],
            config=deployment["networking_config"],
            pod_termination_grace_period_seconds=pod_termination_grace_period_seconds,
        )
        _apply_plugin(ctx, networking_plugin, deployment)
        # Automatically add the metrics sidecar to any deployments. If we encounter a service that
        # wants to disable this we can add a flag.
        if not disable_default_metrics_sidecar:
            _apply_plugin(ctx, metrics(ctx, config=deployment["metrics_config"]), deployment)

        _apply_plugin(ctx, sansshell_sidecar(ctx), deployment)  # go/sod:sansshell

        _apply_plugin(ctx, compose_plugins(
            prestop_all_infra_sidecars(ctx, pod_termination_grace_period_seconds=pod_termination_grace_period_seconds),
            prestop_all_containers(generate_prestop_sleep_action(ctx, DEFAULT_ENVOY_HEALTHCHECK_PROPAGATION_TIME)),
            volume_mount_all_containers(
                "/usr/stripe/bin/kube-prestop",
                read_only=True,
            ),
        ), deployment)


    # Mount ldap volumes to a container if a host mount named etc-lmscache does not exist.
    # Repeatedly mounting the same directory causes a failed deploy.
    # Currently, some services explicitly mount etc-lmscache by calling this plugin.
    # We want to mount this directory to all containers by default without
    # breaking existing services.
    # We cannot add this plugin to the default plugin list above (`all_plugins`) as it requires
    # the plugins provided in the *plugins argument to run beforehand. The default plugin list
    # may already have resulted in mounting of /etc/lmscache
    container = main_container(deployment["pod"])
    if mount_ldap_volumes and container and LDAP_MOUNT_NAME not in container["volume_mounts"]:
        _apply_plugin(ctx, compose_plugins(mount_ldap_host_volumes()), deployment)

    return deployment["render"](ctx, deployment)

def _apply_plugin(ctx, plugin, deployment):
    plugin.update_deployment(ctx, plugin, deployment)
    plugin.update_pod(ctx, plugin, deployment["pod"])

    for container in all_containers(deployment["pod"]):
        plugin.update_containers(ctx, plugin, container)

def deployment_options(**kwargs):
    """
    Defines options for a deployment.

    The arguments map directly to fields on the DeploymentSpec in Kubernetes. Commonly used
    options include `replicas` and `strategy`.

    Args:
        **kwargs: Options to apply to the deployment. These map directly to fields on the Kubernetes
            [DeploymentSpec](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.17/#deploymentspec-v1-apps).

    Returns:
        A plugin that applies the options to a deployment.
    """
    return deployment_plugin(
        _update_deployment_options,
        kwargs = kwargs,
    )

def _update_deployment_options(ctx, plugin, deployment_def):
    deployment_def["kwargs"].update(plugin.kwargs)

def _render_deployment(ctx, deployment_def):
    deployment_def["metadata"] = struct(**deployment_def["metadata"])
    deployment = struct(**deployment_def)

    _validate_deployment(ctx, deployment)

    pod_template = deployment.pod["render"](ctx, deployment.pod)
    _validate_pod_container_resources(ctx, pod_template)

    return Deployment(
        ctx,
        metadata = render_metadata(ctx, deployment.metadata),
        spec = DeploymentSpec(
            ctx,
            selector = render_selector(ctx, deployment.metadata),
            template = pod_template,
            **deployment.kwargs
        ),
    )

def _validate_pod_container_resources(ctx, pod_template):
    containers_with_resources = 0
    first_container_with_resources = None

    if get_render_yaml(ctx):
        containers = pod_template["spec"]["containers"]
    else:
        containers = pod_template.spec.containers

    for container in containers:
        if _container_has_resources(ctx, container):
            containers_with_resources += 1

        if get_render_yaml(ctx):
            name = container["name"]
        else:
            name = container.name

        if containers_with_resources > 1:
            warn(ctx, "".join([
                "More than one container in a Deployment specified requests or limits on resources, which will soon be disallowed. ",
                "The sidecar container with name " + name + " needs to have its CPU and memory resource requirements removed: ",
                "container with name " + first_container_with_resources + " already specified CPU or memory resources for this Deployment. ",
            ]))
        else:
            first_container_with_resources = name

def _container_has_resources(ctx, container):
    if get_render_yaml(ctx):
        if not container["resources"]:
            return False

        if container["resources"]["limits"]:
            if container["resources"]["limits"]["cpu"] or container["resources"]["limits"]["memory"]:
                return True

        if container["resources"]["requests"]:
            if container["resources"]["requests"]["cpu"] or container["resources"]["requests"]["memory"]:
                return True

        return False

    else:
        if not container.resources:
            return False

        if container.resources.limits:
            if container.resources.limits["cpu"] or container.resources.limits["memory"]:
                return True

        if container.resources.requests:
            if container.resources.requests["cpu"] or container.resources.requests["memory"]:
                return True

        return False


def _validate_deployment(ctx, deployment):
    name = deployment.metadata.name
    replicas = deployment.kwargs.get("replicas", None)

    if replicas == None:
        fail("There are no replicas specified in the deployment for %s. Without replicas specified, Kubernetes will fall back on 1 replica which is unsafe. Please explicitly specify replicas in your deployment." % name)

    if replicas == 1 and get_env(ctx) == "prod" and not ("-canary" in name or "canary-" in name):
        warn(ctx, "".join([
            "WARNING: %s is only configured with 1 replica in production. " % name,
            "Please ensure before continuing that this level of risk is acceptable for your service!"
        ]))

    annotations = deployment.metadata.annotations
    _validate_dynamic_replicas_desired_count(ctx, name, replicas, annotations)

    strategy = deployment.kwargs["strategy"]
    _validate_strategy_max_unavailable(ctx, name, replicas, strategy)

# see config/kubernetes/helpers/dynamic.sky
def _validate_dynamic_replicas_desired_count(ctx, name, replicas, annotations):
    enabled = annotations.get("stripe.io/dynamic-replicas-enabled", "no")
    if enabled != "yes":
        return

    desired = annotations.get("stripe.io/dynamic-replicas-count-desired", "")
    if desired != str(replicas):
        fail("%s has dynamic replicas enabled, but its desired count (%s) does not match the given replica count (%s)" % (name, desired, replicas))

# max_unavailable must be less than 1/6th the number of total pods to ensure
# uptime availability across AZs during deployment events (ir-aqua-factorial)
MAX_PERCENT = 16
MIN_REPLICAS_FOR_CHECK = 6
def _validate_strategy_max_unavailable(ctx, name, replicas, strategy):
    if strategy == None:
        return

    # This is not ideal but because we no longer have a wrapped struct with the value/type
    # which wasn't ideal in the first palce we can't modify the code in place neatly.
    if get_render_yaml(ctx):
        # Only RollingUpdate deployment strategies are checked.
        if strategy["type"] != "RollingUpdate":
            return

        max_unavailable = strategy["rollingUpdate"]["maxUnavailable"]
        if max_unavailable == None:
            fail("Deployment %s specifies a RollingUpdate strategy without maxUnavailable" % name)

        if type(max_unavailable) == "string" and len(max_unavailable) > 0:
            if "%" in max_unavailable:
                percent = int(max_unavailable.split("%")[0])
                _validate_strategy_max_unavailable_warning(ctx, name, replicas, percent)
            else:
                literal = int(max_unavailable)
                percent = 0
                if replicas > 0:
                    percent = 100 * literal // replicas
                _validate_strategy_max_unavailable_warning(ctx, name, replicas, percent, literal)
        elif type(max_unavailable) == "int" and max_unavailable > 0:
            percent = 0
            if replicas > 0:
                percent = 100 * max_unavailable // replicas
            _validate_strategy_max_unavailable_warning(ctx, name, replicas, percent, max_unavailable)
    else:
        # Only RollingUpdate deployment strategies are checked.
        if strategy.type != "RollingUpdate":
            return

        max_unavailable = strategy.rollingUpdate.maxUnavailable
        if max_unavailable == None:
            fail("Deployment %s specifies a RollingUpdate strategy without maxUnavailable" % name)

        if max_unavailable.type == 1 and len(max_unavailable.strVal) > 0:
            if "%" in max_unavailable.strVal:
                percent = int(max_unavailable.strVal.split("%")[0])
                _validate_strategy_max_unavailable_warning(ctx, name, replicas, percent)
            else:
                literal = int(max_unavailable.strVal)
                percent = 0
                if replicas > 0:
                    percent = 100 * literal // replicas
                _validate_strategy_max_unavailable_warning(ctx, name, replicas, percent, literal)
        elif max_unavailable.intVal != None:
            literal = max_unavailable.intVal
            percent = 0
            if replicas > 0:
                percent = 100 * literal // replicas
            _validate_strategy_max_unavailable_warning(ctx, name, replicas, percent, literal)

def _validate_strategy_max_unavailable_warning(ctx, name, replicas, percent, literal=None):
    if replicas < MIN_REPLICAS_FOR_CHECK:
        return

    # Skip for blue-green services
    if percent == 100 and get_blue_green_color(ctx) != None:
        return

    if percent > MAX_PERCENT:
        if literal != None:
            minLiteral = (MAX_PERCENT * replicas) // 100
            warn(ctx, "".join([
                "WARNING: The MaxUnavailable value for %s " % name,
                "is above the threshold of %d%% " % MAX_PERCENT,
                "for Deployments with more than %d replicas. " % MIN_REPLICAS_FOR_CHECK,
                "The specified value is %d, corresponding to %d%% of %d replicas. " % (literal, percent, replicas),
                "Please reduce the MaxUnavailable value to %d or below. " % minLiteral
            ]))
        else:
            warn(ctx, "".join([
                "WARNING: The MaxUnavailable value for %s " % name,
                "is above the threshold of %d%% " % MAX_PERCENT,
                "for Deployments with more than %d replicas. " % MIN_REPLICAS_FOR_CHECK,
                "The specified value is %d%%. " % percent,
                "Please reduce the MaxUnavailable percent below the threshold."
            ]))
