load("config/kubernetes/apps/deployment.sky", "deployment")
load("config/kubernetes/core/container.sky", "container", "init_container")
load("config/kubernetes/core/env_var.sky", "container_env_vars")
load("config/kubernetes/core/volume.sky", "mount_pod_volume", "volume_mount")
load("config/kubernetes/helpers/images.sky", "image")
load("config/kubernetes/apps/strategy.sky", "rolling_update_strategy")
load("config/kubernetes/helpers/aws_instance_sizes.sky", "m5d_xlarge")
load("config/kubernetes/helpers/context.sky", "get_cluster", "get_env")
load("config/kubernetes/helpers/quantities.sky", "cores", "gigabytes")
load("config/kubernetes/helpers/healthcheck.sky", "healthchecked_service")
load("config/kubernetes/helpers/security.sky", "add_security_groups", "run_as_unprivileged")
load("config/kubernetes/sidecars/confidant.sky", "raw_secret")
load("config/kubernetes/stripe.sky", "stripe_pod")
load("config/kubernetes/plugins/compose.sky", "compose_plugins")

def env_configs(ctx):
    mysql_datasource_url_template = "jdbc:mysql://%s:%s/datahub?verifyServerCertificate=false&useSSL=true&useUnicode=yes&characterEncoding=UTF-8&enabledTLSProtocols=TLSv1.2"
    schema_registry_envoy_url = "http://schema-registry.service.envoy:10080/contexts/.datahub"
    mysql_port = "3306"
    es_sproxy_host = "sproxy.service.envoy"
    es_sproxy_port = "10080"
    es_cluster_name = "searchdatahub"
    if get_env(ctx) == "qa":
        qa_mysql_host = "qa-datahubdb.ckfnlamw54se.us-west-2.rds.amazonaws.com"
        kafka_datahub = "PLAINTEXT://kafka-datahub-northwest-green.service.qa-northwest.consul:9092"
        return {
            "replicas": 5,
            "mysql_host": qa_mysql_host,
            "ebean_datasource_host": qa_mysql_host + ":" + mysql_port,
            "ebean_datasource_url": mysql_datasource_url_template % (qa_mysql_host, mysql_port),
            "kafka_bootstrap_server": kafka_datahub,
            "kafka_schemaregistry_url": schema_registry_envoy_url,
            "elasticsearch_host": es_sproxy_host,
            "elasticsearch_port": es_sproxy_port,
            "elasticsearch_path_prefix": "/" + es_cluster_name,
        }
    else:
        prod_mysql_host = "datahubdb.ckfnlamw54se.us-west-2.rds.amazonaws.com"
        kafka_datahub = "PLAINTEXT://kafka-datahub-northwest-green.service.northwest.consul:9092"
        return {
            "replicas": 10,
            "mysql_host": prod_mysql_host,
            "ebean_datasource_host": prod_mysql_host + ":" + mysql_port,
            "ebean_datasource_url": mysql_datasource_url_template % (prod_mysql_host, mysql_port),
            "kafka_bootstrap_server": kafka_datahub,
            "kafka_schemaregistry_url": schema_registry_envoy_url,
            "elasticsearch_host": es_sproxy_host,
            "elasticsearch_port": es_sproxy_port,
            "elasticsearch_path_prefix": "/" + es_cluster_name,
        }

def add_jmxfetch_sidecar(ctx, service_name, jmx_port, props_volume, yaml_file):
    return compose_plugins(
        container(
            name = "jmxfetch",
            image = image(
                ctx,
                "third-party/jmxfetch",
                label = "latest",
            ),
            command = [
                "java",
                "-classpath",
                "/jmxfetch-0.14.0-jar-with-dependencies.jar",
                "org.datadog.jmxfetch.App",
                "--check",
                yaml_file,
                "--check_period",
                "15000",
                "--conf_directory",
                props_volume,
                "--log_level",
                "INFO",
                "--log_location",
                "/jmxfetch/jmxfetch-datahub-gms.log",
                "--reporter",
                "statsd:127.0.0.1:8200",
                "--status_location",
                "/jmxfetch/status_datahub_gms.yaml",
                "collect",
            ],
            plugins = [
                container_env_vars(
                    vars = {
                        "JAVA_OPTS": " ".join([
                            "-Xms50m",
                            "-Xmx200m",
                        ]),
                    },
                ),
            ],
        ),
        mount_pod_volume("/jmxfetch", container_name = "jmxfetch", mount_args = {"read_only": False}),
        mount_pod_volume(props_volume, container_name = "jmxfetch"),
    )

# Canary to one replica
def canary(ctx):
    return _service(ctx, replicas = 1, suffix = "-canary")

# Deploy to the rest of the fleet
def main(ctx):
    return _service(ctx, replicas = env_configs(ctx)["replicas"])

def _service(ctx, replicas, suffix = ""):
    container_image = image(
        ctx,
        artifact = "datahub-image",
    )
    PROPS_VOLUME = "/pay/jmxfetch-config"
    common_gms_env_vars = {
        "DATASET_ENABLE_SCSI": "false",
        "EBEAN_DATASOURCE_USERNAME": "datahub",
        "EBEAN_DATASOURCE_HOST": env_configs(ctx)["ebean_datasource_host"],
        "EBEAN_DATASOURCE_URL": env_configs(ctx)["ebean_datasource_url"],
        "EBEAN_DATASOURCE_DRIVER": "com.mysql.jdbc.Driver",
        "KAFKA_BOOTSTRAP_SERVER": env_configs(ctx)["kafka_bootstrap_server"],
        "KAFKA_SCHEMAREGISTRY_URL": env_configs(ctx)["kafka_schemaregistry_url"],
        "ELASTICSEARCH_HOST": env_configs(ctx)["elasticsearch_host"],
        "ELASTICSEARCH_PORT": env_configs(ctx)["elasticsearch_port"],
        "ELASTICSEARCH_PATH_PREFIX": env_configs(ctx)["elasticsearch_path_prefix"],
        "GRAPH_SERVICE_IMPL": "elasticsearch",
        "LOG_DIR": "/datahub/datahub-gms/logs",
        "ENTITY_REGISTRY_CONFIG_PATH": "/datahub/datahub-gms/resources/entity-registry.yml",
        "MAE_CONSUMER_ENABLED": "false",
        "MCE_CONSUMER_ENABLED": "false",
        "UI_INGESTION_ENABLED": "false",
        "JAVA_OPTS": "-Xms4g -Xmx4g",
        "METADATA_CHANGE_EVENT_NAME": "datahub.metadata_change_event",
        "KAFKA_MCE_TOPIC_NAME": "datahub.metadata_change_event",
        "METADATA_AUDIT_EVENT_NAME": "datahub.metadata_audit_event",
        "FAILED_METADATA_CHANGE_EVENT_NAME": "datahub.failed_metadata_change_event",
        "KAFKA_FMCE_TOPIC_NAME": "datahub.failed_metadata_change_event",
        "METADATA_CHANGE_PROPOSAL_TOPIC_NAME": "datahub.metadata_change_proposal",
        "DATAHUB_ANALYTICS_ENABLED": "true",
        "DATAHUB_USAGE_EVENT_NAME": "datahub.usage_event",
        "METADATA_CHANGE_LOG_VERSIONED_TOPIC_NAME": "datahub.metadata_changelog_versioned",
        "METADATA_CHANGE_LOG_TIMESERIES_TOPIC_NAME": "datahub.metadata_changelog_timeseries",
        "JMX_OPTS": "-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=8082",
        # Hook up Open Telemetry for request tracing
        "OTEL_AGENT": "-javaagent:/datahub/datahub-gms/bin/opentelemetry-javaagent-all.jar",
        "OTEL_TRACES_EXPORTER": "otlp",
        "OTEL_EXPORTER_OTLP_ENDPOINT": "http://refinery-grpc.service.envoy:10080",
        "OTEL_SERVICE_NAME": "datahub-gms",
    }

    service_port = 8080
    deploy = deployment(
        ctx,
        stripe_pod(
            name = "datahub-gms" + suffix,
            namespace = "datahub",
            command = ["./datahub-gms/scripts/stripe-start.sh"],
            # m5.xlarge instances have 4 cores and 16 GB of memory
            instance_type = m5d_xlarge,
            image = container_image,
        ),
        healthchecked_service(
            name = "datahub-gms",
            port = service_port,
            path = "/health",
            # bump up startup probe threshold as gms often spends time re-indexing etc at bootstrap
            # which bumps against the default 5 min startup_probe_failure_threshold
            startup_probe_failure_threshold = 900,
        ),
        # init container to run MySQL init
        init_container(
            name = "datahub-gms-initmysql",
            command = ["/datahub/datahub-gms/scripts/stripe-init.sh"],
            cpu = cores(1),
            memory = gigabytes(1),
        ),
        container_env_vars(
            vars = {
                "MYSQL_USERNAME": "datahub",
                "MYSQL_HOST": env_configs(ctx)["mysql_host"],
                "DATAHUB_DB_NAME": "datahub",
            },
            container_name = "datahub-gms-initmysql",
        ),
        # init container to copy the jmx fetch yaml to the properties volume so that JMX fetch
        # can access it
        init_container(
            name = "copy-jmxfetch-yaml",
            command = ["cp", "/datahub/datahub-gms/resources/stripe-jmxfetch.yaml", PROPS_VOLUME],
            cpu = cores(1),
            memory = gigabytes(1),
            plugins = [
                volume_mount(PROPS_VOLUME, read_only = False),
            ],
        ),
        # configure the jmx fetch sidecar container
        add_jmxfetch_sidecar(ctx, "datahub-gms", "8082", PROPS_VOLUME, "stripe-jmxfetch.yaml"),
        add_security_groups("datahub"),
        raw_secret(
            filename = "db_root_password.txt",
            key = "datahub/mysqldb/db_root_password",
            container_names = ["datahub-gms-initmysql", "datahub-gms", "datahub-gms-canary"],
        ),
        # set various env vars on both datahub-gms and datahub-gms-canary
        container_env_vars(
            vars = common_gms_env_vars,
            container_name = "datahub-gms",
        ),
        container_env_vars(
            vars = common_gms_env_vars,
            container_name = "datahub-gms-canary",
        ),
        run_as_unprivileged(),  # this runs the containers as 'stripe-service'
        replicas = replicas,
        # details on this: https://skycfg.corp.stripe.com/rollouts
        # these numbers allow us to have sufficient number of healthy instances
        # in each of our deployment stages
        strategy = rolling_update_strategy(
            # max_unavailable must be less than 1/6th the number of total pods to ensure
            # uptime availability across AZs during deployment events (ir-aqua-factorial)
            max_unavailable = "16%" if replicas > 6 else 1,
            max_surge = "50%",
        ),
        shared_msp = True,
    )
    return [deploy]
